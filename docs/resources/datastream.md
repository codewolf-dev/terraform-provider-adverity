---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "adverity_datastream Resource - adverity"
subcategory: ""
description: |-
  Manages a datastream.
---

# adverity_datastream (Resource)

Manages a datastream.

## Example Usage

```terraform
resource "adverity_authorization" "sprinklr" {
  name     = "sprinklr"
  stack_id = 1

  connection_type_id = 187 # Sprinklr

  parameters = {
    domain = "your-spinklr-space"
  }
}

resource "adverity_datastream" "datastream" {
  name     = "sprinklr"
  auth_id  = adverity_authorization.sprinklr.id
  stack_id = 1

  datastream_type_id = 576 # Sprinklr

  datatype = "Live" # Either "Live" to enable scheduling or "Staging" to disable scheduling

  enabled = false # Enable data transfers to destination

  parameters = {
    widget_query = jsondecode(file("path/to/file.json")) # Pass parameters as Terraform types instead of string
  }

  schedule {
    cron_preset       = "CRON_EVERY_DAY"
    cron_start_of_day = "03:33:33"
    time_range_preset = 0 # Custom
    fixed_start       = "2025-01-01"
  }
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `datastream_type_id` (Number) Numeric identifier of the datastream type.
- `name` (String) Name of the datastream.

### Optional

- `auth_id` (Number) Numeric identifier of the connection.
- `datatype` (String) Type of the datastream ('Live' or 'Staging').
- `description` (String) Description of the datastream.
- `enabled` (Boolean) Whether to enable the datastream.
- `extract_name_keys` (String) Date column to use for managing extract names.
- `is_insights_mediaplan` (Boolean) Whether to treat extracts as insights mediaplans.
- `manage_extract_names` (Boolean) Whether to manage extract names.
- `parameters` (Dynamic) Additional datastream parameters.
- `retention_number` (Number) Number of fetches/extracts/days to retain.
- `retention_type` (Number) Numeric identifier of the retention type.
- `schedule` (Block List) Schedule the datastream. (see [below for nested schema](#nestedblock--schedule))
- `stack_id` (Number) Numeric identifier of the workspace.

### Read-Only

- `id` (Number) Numeric identifier of the datastream.
- `last_updated` (String) Timestamp of the last Terraform update of the datastream.

<a id="nestedblock--schedule"></a>
### Nested Schema for `schedule`

Optional:

- `cron_interval` (Number) Cron interval.
- `cron_interval_start` (Number) Cron interval start.
- `cron_preset` (String) Cron preset.
- `cron_start_of_day` (String) Cron start of day.
- `cron_type` (String) Cron type.
- `delta_interval` (Number) Delta interval.
- `delta_interval_start` (Number) Delta interval start.
- `delta_start_of_day` (String) Delta start of day.
- `delta_type` (Number) Delta type.
- `fixed_end` (String) Fixed end.
- `fixed_start` (String) Fixed start.
- `not_before_date` (String) Not before date.
- `not_before_time` (String) Not before time.
- `offset_days` (Number) Offset days.
- `time_range_preset` (Number) Time range preset.

## Import

Import is supported using the following syntax:

```shell
# Datastream can be imported by specifying it's numeric id.
terraform import adverity_datastream.example 123
```
